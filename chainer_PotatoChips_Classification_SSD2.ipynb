{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chainer_PotatoChips_Classification_SSD2",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mogamin/chainer-examples/blob/master/chainer_PotatoChips_Classification_SSD2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Nu__Bz5_MfOb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "346e72fd-b369-4805-9a08-44131e438a73"
      },
      "cell_type": "code",
      "source": [
        "![ ! -e ./data ] && curl -L \"https://rebrand.ly/dllab2018-hackathon-cv\" -o data.tar.gz && gzip -d -c data.tar.gz | tar xf -\n",
        "\n",
        "# chainer,chainercv,cudaののセットアップ\n",
        "!apt-get install -y -qq libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!pip install cupy-cuda80==4.3.0 \n",
        "!pip install chainer==4.3.0\n",
        "!pip install chainercv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cupy-cuda80==4.3.0 in /usr/local/lib/python3.6/dist-packages (4.3.0)\r\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80==4.3.0) (1.11.0)\r\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80==4.3.0) (0.3)\r\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80==4.3.0) (1.14.5)\n",
            "Requirement already satisfied: chainer==4.3.0 in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer==4.3.0) (1.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from chainer==4.3.0) (3.0.4)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer==4.3.0) (1.14.5)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer==4.3.0) (3.6.1)\n",
            "Requirement already satisfied: cupy-cuda80<5.0.0,>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from chainer==4.3.0) (4.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0.0->chainer==4.3.0) (39.1.0)\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80<5.0.0,>=4.3.0->chainer==4.3.0) (0.3)\n",
            "Requirement already satisfied: chainercv in /usr/local/lib/python3.6/dist-packages (0.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from chainercv) (4.0.0)\n",
            "Requirement already satisfied: chainer>=4.0 in /usr/local/lib/python3.6/dist-packages (from chainercv) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->chainercv) (0.45.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer>=4.0->chainercv) (1.14.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from chainer>=4.0->chainercv) (3.0.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from chainer>=4.0->chainercv) (1.11.0)\n",
            "Requirement already satisfied: cupy-cuda80<5.0.0,>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from chainer>=4.0->chainercv) (4.3.0)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer>=4.0->chainercv) (3.6.1)\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80<5.0.0,>=4.3.0->chainer>=4.0->chainercv) (0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0.0->chainer>=4.0->chainercv) (39.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yLrEEufoNDYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cc568b9b-0f1c-4631-9c73-f4a3acd9f6aa"
      },
      "cell_type": "code",
      "source": [
        "# GPU環境の確認\n",
        "import chainer\n",
        "print('GPU availability:', chainer.cuda.available)\n",
        "print('cuDNN availablility:', chainer.cuda.cudnn_enabled)\n",
        "\n",
        "# クリーニング\n",
        "!rm -rf result/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU availability: True\n",
            "cuDNN availablility: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gVqu0HewNHpa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 乱数表の固定化\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "RANDOM_SEED = 0\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "if chainer.cuda.available:\n",
        "    chainer.cuda.cupy.random.seed(RANDOM_SEED)\n",
        "\n",
        "# 実行時間の生成\n",
        "import datetime\n",
        "now = (datetime.datetime.now() + datetime.timedelta(hours=+9)).strftime('%Y%m%d-%H%M%S')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KP_Iic57NbvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "115765d2-f277-4127-ab6c-8fc91492110a"
      },
      "cell_type": "code",
      "source": [
        "#!curl -sc /tmp/cookie \"https://drive.google.com/uc?export=download&id=1DXBavZ6yst1Udhqld816vScDhk-MrtoB\" > /dev/null\n",
        "#!awk '/_warning_/ {print $NF}' /tmp/cookie\n",
        "#!curl -Lb /tmp/cookie \"https://drive.google.com/uc?export=download&confirm=Wm07&id=1DXBavZ6yst1Udhqld816vScDhk-MrtoB\" -o model_potato_20180816-134135_gpu.npz\n",
        "#!ls -l\n",
        "#!mkdir -p bbox-images"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   388    0   388    0     0    388      0 --:--:-- --:--:-- --:--:--  4459\n",
            "100  913M    0  913M    0     0   130M      0 --:--:--  0:00:07 --:--:--  137M\n",
            "total 4467480\n",
            "drwxrwxr-x 5 1008 1008       4096 Jun 19 13:19 data\n",
            "lrwxrwxrwx 1 root root          8 Aug 15 20:56 datalab -> /content\n",
            "-rw-r--r-- 1 root root 3616797934 Aug 20 05:47 data.tar.gz\n",
            "-rw-r--r-- 1 root root  957880472 Aug 20 07:04 model_potato_20180816-134135_gpu.npz\n",
            "drwxr-xr-x 2 root root       4096 Aug 15 20:56 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ws8WvyK6NOo8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "import chainer\n",
        "from chainer.datasets import ConcatenatedDataset\n",
        "from chainer.datasets import TransformDataset\n",
        "from chainer.optimizer_hooks import WeightDecay\n",
        "from chainer import serializers\n",
        "from chainer import training\n",
        "from chainer.training import extensions\n",
        "from chainer.training import triggers\n",
        "\n",
        "from chainercv.datasets import voc_bbox_label_names\n",
        "from chainercv.datasets import VOCBboxDataset\n",
        "from chainercv.extensions import DetectionVOCEvaluator\n",
        "from chainercv.links.model.ssd import GradientScaling\n",
        "from chainercv.links.model.ssd import multibox_loss\n",
        "from chainercv.links import SSD300\n",
        "from chainercv.links import SSD512\n",
        "from chainercv import transforms\n",
        "\n",
        "from chainercv.links.model.ssd import random_crop_with_bbox_constraints\n",
        "from chainercv.links.model.ssd import random_distort\n",
        "from chainercv.links.model.ssd import resize_with_random_interpolation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9mg9QFQONP0t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MultiboxTrainChain(chainer.Chain):\n",
        "\n",
        "    def __init__(self, model, alpha=1, k=3):\n",
        "        super(MultiboxTrainChain, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.model = model\n",
        "        self.alpha = alpha\n",
        "        self.k = k\n",
        "\n",
        "    def __call__(self, imgs, gt_mb_locs, gt_mb_labels):\n",
        "        mb_locs, mb_confs = self.model(imgs)\n",
        "        loc_loss, conf_loss = multibox_loss(mb_locs, mb_confs, gt_mb_locs, gt_mb_labels, self.k)\n",
        "        loss = loc_loss * self.alpha + conf_loss\n",
        "\n",
        "        chainer.reporter.report(\n",
        "            {'loss': loss, 'loss/loc': loc_loss, 'loss/conf': conf_loss},\n",
        "            self)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U_Z9qjiuNWF6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! rm -f bbox-images/*\n",
        "\n",
        "from chainercv.transforms import resize\n",
        "from chainercv.utils.image import write_image\n",
        "\n",
        "class Transform(object):\n",
        "\n",
        "    def __init__(self, coder, size, mean):\n",
        "        # to send cpu, make a copy\n",
        "        self.coder = copy.copy(coder)\n",
        "        self.coder.to_cpu()\n",
        "\n",
        "        self.size = size\n",
        "        self.mean = mean\n",
        "        self.count = 0\n",
        "\n",
        "    def __call__(self, in_data):\n",
        "        img, bbox, label = in_data\n",
        "        #write_image(img, './bbox-images/'+str(self.count)+'_0.png')\n",
        "        img = resize(img, (224, 224))\n",
        "\n",
        "        # 1. Color augmentation\n",
        "        img = random_distort(img)\n",
        "        #write_image(img, './bbox-images/'+str(self.count)+'_1.png')\n",
        "\n",
        "        # 2. Random expansion\n",
        "        if np.random.randint(2):\n",
        "            img, param = transforms.random_expand(img, fill=self.mean, return_param=True)\n",
        "            bbox = transforms.translate_bbox(bbox, y_offset=param['y_offset'], x_offset=param['x_offset'])\n",
        "        #write_image(img, './bbox-images/'+str(self.count)+'_2.png')\n",
        "\n",
        "        # 3. Random cropping\n",
        "        img, param = random_crop_with_bbox_constraints(img, bbox, return_param=True)\n",
        "        bbox, param = transforms.crop_bbox(\n",
        "            bbox, y_slice=param['y_slice'], x_slice=param['x_slice'],\n",
        "            allow_outside_center=False, return_param=True)\n",
        "        label = label[param['index']]\n",
        "        #write_image(img, './bbox-images/'+str(self.count)+'_3.png')\n",
        "\n",
        "        # 4. Resizing with random interpolatation\n",
        "        _, H, W = img.shape\n",
        "        img = resize_with_random_interpolation(img, (self.size, self.size))\n",
        "        bbox = transforms.resize_bbox(bbox, (H, W), (self.size, self.size))\n",
        "        #write_image(img, './bbox-images/'+str(self.count)+'_4.png')\n",
        "\n",
        "        # 5. Random horizontal flipping\n",
        "        img, params = transforms.random_flip(img, x_random=True, return_param=True)\n",
        "        bbox = transforms.flip_bbox(bbox, (self.size, self.size), x_flip=params['x_flip'])\n",
        "        #write_image(img, './bbox-images/'+str(self.count)+'_5.png')\n",
        "\n",
        "        # Preparation for SSD network\n",
        "        #img -= self.mean\n",
        "        mb_loc, mb_label = self.coder.encode(bbox, label)\n",
        "        #write_image(img, './bbox-images/'+str(self.count)+'_6.png')\n",
        "\n",
        "        self.count += 1\n",
        "        return img, mb_loc, mb_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CVFEaqnkNXDK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "voc_bbox_label_names = (\n",
        "    'ususio-BIGBAG','ususio-LBIG','ususio-NORMAL',\n",
        "    'consome-NORMAL','consome-LBIG','consome-BIGBAG',\n",
        "    'k-soy-BIGBAG','k-soy-LBAG','k-soy-NORMAL')\n",
        "\n",
        "model = SSD300(n_fg_class=len(voc_bbox_label_names), pretrained_model='./model_potato_20180816-134135_gpu.npz')\n",
        "#model = SSD300(n_fg_class=len(voc_bbox_label_names), pretrained_model='imagenet')\n",
        "#model = SSD300(n_fg_class=20, pretrained_model='imagenet')\n",
        "\n",
        "model.use_preset('evaluate')\n",
        "train_chain = MultiboxTrainChain(model)\n",
        "chainer.cuda.get_device_from_id(0).use()\n",
        "model.to_gpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s0XlwKAbSFNc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpy\n",
        "import os\n",
        "from chainercv.chainer_experimental.datasets.sliceable import GetterDataset\n",
        "from chainercv.utils import generate_random_bbox\n",
        "import six\n",
        "\n",
        "from PIL import Image\n",
        "def _read_image_as_array(path, dtype):\n",
        "    f = Image.open(path)\n",
        "    try:\n",
        "        image = numpy.asarray(f, dtype=dtype)\n",
        "    finally:\n",
        "        # Only pillow >= 3.0 has 'close' method\n",
        "        if hasattr(f, 'close'):\n",
        "            f.close()\n",
        "    return image\n",
        "\n",
        "\n",
        "def _postprocess_image(image):\n",
        "    if image.ndim == 2:\n",
        "        # image is greyscale\n",
        "        image = image[..., None]\n",
        "    return image.transpose(2, 0, 1)\n",
        "  \n",
        "  \n",
        "class MyBboxDataset(GetterDataset):\n",
        "  def __init__(self, pairs, root='.', dtype=None, label_dtype=numpy.int32):\n",
        "    super(MyBboxDataset, self).__init__()\n",
        "    \n",
        "    # register getter methods\n",
        "    self.add_getter('img', self.get_image)\n",
        "    #self.add_getter(('bbox', 'label'), self.get_annotation)\n",
        "    self.add_getter(('bbox', 'label', 'difficult'), self.get_annotation)\n",
        "    \n",
        "    if isinstance(pairs, six.string_types):\n",
        "        pairs_path = pairs\n",
        "        with open(pairs_path) as pairs_file:\n",
        "            pairs = []\n",
        "            for i, line in enumerate(pairs_file):\n",
        "                pair = line.strip().split()\n",
        "                if len(pair) != 2:\n",
        "                    raise ValueError(\n",
        "                        'invalid format at line {} in file {}'.format(\n",
        "                            i, pairs_path))\n",
        "                pairs.append((pair[0], int(pair[1])))\n",
        "    self._pairs = pairs\n",
        "    self._root = root\n",
        "    self._dtype = np.float32\n",
        "    self._label_dtype = label_dtype    \n",
        "    self.keys = ('img', 'bbox', 'label')\n",
        "    self.bbox = np.array([[ 50.0 , 50.0 , 170.0 , 170.0 ]])\n",
        "    ##generate_random_bbox(1, (224, 224), 180, 190)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self._pairs)\n",
        "  \n",
        "  def get_image(self, i):\n",
        "    path, int_label = self._pairs[i]\n",
        "    full_path = os.path.join(self._root, path)\n",
        "    image = _read_image_as_array(full_path, self._dtype)\n",
        "    return _postprocess_image(image)\n",
        "      \n",
        "  def get_annotation(self, i):\n",
        "    #print(\"i=\",i)\n",
        "    #print(type(self.bbox))\n",
        "    #print(self.bbox.shape)\n",
        "\n",
        "    path, int_label = self._pairs[i]\n",
        "    label = numpy.array([int_label], dtype=self._label_dtype)\n",
        "    #label = int_label\n",
        "    #print(\"label=\",label)\n",
        "        \n",
        "    # generate dummy annotations\n",
        "    #bbox = generate_random_bbox(1, (224, 224), 180, 190)\n",
        "    return self.bbox, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rdcb97jtSKqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "19ab3255-d714-42f8-bc68-ed0e0f40f63c"
      },
      "cell_type": "code",
      "source": [
        "if 1:\n",
        "  BATCHSIZE=32\n",
        "  train = MyBboxDataset('data/train/train_labels.txt', 'data/train/images/')\n",
        "  train = TransformDataset(train,  Transform(model.coder, model.insize, model.mean))\n",
        "  train_iter = chainer.iterators.MultiprocessIterator(train, BATCHSIZE)\n",
        "  \n",
        "\n",
        "  #test = LabeledImageDataset('data/valid/valid_labels.txt', root='data/valid/images/')\n",
        "  #test = TransformDataset(test, ImageResizeTransform())\n",
        "  test = VOCBboxDataset(\n",
        "      year='2007', split='test',\n",
        "      use_difficult=True, return_difficult=True)\n",
        "\n",
        "  test_iter = chainer.iterators.SerialIterator(test, BATCHSIZE, repeat=False, shuffle=False)\n",
        "  \n",
        "if 0:\n",
        "  train = TransformDataset(\n",
        "      ConcatenatedDataset(\n",
        "          VOCBboxDataset(year='2007', split='trainval'),\n",
        "          VOCBboxDataset(year='2012', split='trainval')\n",
        "      ),\n",
        "      Transform(model.coder, model.insize, model.mean))\n",
        "\n",
        "  train_iter = chainer.iterators.MultiprocessIterator(train, 32)\n",
        "\n",
        "  test = VOCBboxDataset(year='2007', split='test', use_difficult=True, return_difficult=True)\n",
        "  test_iter = chainer.iterators.SerialIterator(test, 32, repeat=False, shuffle=False)\n",
        "\n",
        "  from chainercv.visualizations import vis_bbox\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  #img, bbox, label = train[0]\n",
        "  #print(bbox.shape)\n",
        "  #print(label.shape)\n",
        "  #vis_bbox(img, bbox, label, label_names=voc_bbox_label_names)\n",
        "  #plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ...\n",
            "From: http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
            "To: /content/.chainer/dataset/_dl_cache/c320d1dc0cd031efc99e256bf21d57a6\n",
            "  %   Total    Recv       Speed  Time left\n",
            "100  430MiB  430MiB   4332KiB/s    0:00:00"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1gJeqPi2SPJs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initial lr is set to 1e-3 by ExponentialShift\n",
        "\n",
        "#optimizer = chainer.optimizers.MomentumSGD()\n",
        "#optimizer.setup(train_chain)\n",
        "#for param in train_chain.params():\n",
        "#    if param.name == 'b':\n",
        "#        param.update_rule.add_hook(GradientScaling(2))\n",
        "#    else:\n",
        "#        param.update_rule.add_hook(WeightDecay(0.0005))\n",
        "        \n",
        "optimizer = chainer.optimizers.Adam()\n",
        "optimizer.setup(model)\n",
        "  \n",
        "updater = training.updaters.StandardUpdater(train_iter, optimizer, device=0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BCxP-yHGSSPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1115
        },
        "outputId": "3a4f80df-84cd-452d-8965-7627d443f479"
      },
      "cell_type": "code",
      "source": [
        "trainer = training.Trainer(updater, (10, 'epoch'), 'result/ssd')\n",
        "#trainer.extend(extensions.ExponentialShift('lr', 0.1, init=1e-4), trigger=(1,'epoch'))\n",
        "\n",
        "#trainer.extend(\n",
        "#    extensions.ExponentialShift('lr', 0.1, init=1e-3),\n",
        "#    trigger=triggers.ManualScheduleTrigger([3,4], 'epoch'))\n",
        "\n",
        "#trainer.extend(\n",
        "#    DetectionVOCEvaluator(\n",
        "#        test_iter, model, use_07_metric=True,\n",
        "#        label_names=voc_bbox_label_names),\n",
        "#    trigger=(300, 'iteration'))\n",
        "\n",
        "log_interval = 100, 'iteration'\n",
        "trainer.extend(extensions.LogReport(trigger=log_interval))\n",
        "trainer.extend(extensions.observe_lr(), trigger=log_interval)\n",
        "trainer.extend(extensions.PrintReport(\n",
        "    ['epoch', 'iteration', 'lr', 'elapsed_time','main/loss', 'main/loss/loc', 'main/loss/conf', 'validation/main/map']),\n",
        "    trigger=log_interval)\n",
        "trainer.extend(extensions.ProgressBar(update_interval=500))\n",
        "\n",
        "#trainer.extend(extensions.snapshot(), trigger=(10000, 'iteration'))\n",
        "trainer.extend(\n",
        "    extensions.snapshot_object(model, 'model_iter_{.updater.iteration}'),\n",
        "    trigger=(100, 'iteration'))\n",
        "\n",
        "trainer.run()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[J"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception in main training loop: __call__() takes 2 positional arguments but 4 were given\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/chainer/training/trainer.py\", line 306, in run\n",
            "    update()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/chainer/training/updaters/standard_updater.py\", line 149, in update\n",
            "    self.update_core()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/chainer/training/updaters/standard_updater.py\", line 160, in update_core\n",
            "    optimizer.update(loss_func, *in_arrays)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/chainer/optimizer.py\", line 650, in update\n",
            "    loss = lossfun(*args, **kwds)\n",
            "Will finalize trainer extensions and updater before reraising the exception.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-8898746a245f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     trigger=(100, 'iteration'))\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/training/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 print('Will finalize trainer extensions and updater before '\n\u001b[1;32m    319\u001b[0m                       'reraising the exception.', file=sys.stderr)\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/training/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mreporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/training/updaters/standard_updater.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/training/updaters/standard_updater.py\u001b[0m in \u001b[0;36mupdate_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/optimizer.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, lossfun, *args, **kwds)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlossfun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0muse_cleargrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_use_cleargrads'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_cleargrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleargrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __call__() takes 2 positional arguments but 4 were given"
          ]
        }
      ]
    }
  ]
}